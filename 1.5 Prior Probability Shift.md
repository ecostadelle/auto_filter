# 1.5 Prior Probability Shift

Prior probability shift is a common issue in simple generative models. A popular
example stems from the availability of naive Bayes models for the filtering of spam
email. In cases of prior probability shift, an assumption is made that a causal
model of the form $P(x|y)P(y)$ is valid (see figure 1.3) and the Bayes rule is used to
inferentially obtain $P(y|x)$. Naive Bayes is one model that makes this assumption.
The difficulty occurs if the distribution $P(y)$ changes between training and test
situations. As y is what we are trying to predict it is unsurprising that this form
of dataset shift will affect the prediction.

For a known shift in $P(y)$, prior probability shift is easy to correct for. As it is
presumed that $P(x|y)$ does not change, this model can be learned directly from
the training data. However the learned $P_{tr}(y)$ is no longer valid, and needs to be
replaced by the known prior distribution in the test scenario $P_{te}(y)$.
If, however, the distribution $P_{te}(y)$ is not known for the test scenario, then the
situation is a little more complicated. Making a prediction

$$
P(y|x) = \frac{P(x|y)P(y)}{P(x)}
$$

is not possible without knowledge of $P(y)$. But given the model $P(x|y)$ and the
covariates for the test data, certain distributions over y are more or less likely.
Consider the spam filter example again. If in the test data, the vast majority
of the emails contain spammy words, rather than hammy words, we would rate
$P(spam) = 0$ as an unlikely model compared with other models such as $P(spam) = 0.7$. 
In saying this we are implicitly using some a priori model of what distributions
$P(spam)$ are acceptable to us, and then using the data to refine this model.

Restated, to account for prior probability shift where the precise shift is unknown
a prior distribution over valid $P(y)$ can be specified, and the posterior distribution
over $P(y)$ computed from the test covariate data. Then the predicted target is given
by the sum of the predictions obtained for each $P(y)$ weighted by the posterior
probability of $P(y)$.

Suppose $P(y)$ is parameterized by $\theta$, and a prior distribution for P(y) is defined
through a prior on the parameters $P(\theta)$. Also assume that the model $P_{tr}(x|y)$ has
been learned from the training data. Then the prediction taking into account the
parameter uncertainty and the observed test data is

$$
P(y_1|\{x_i\}) = \int d \theta P(y_1|x_1, \theta) P_{te}(\theta|\{x_i\}) \\
= \int d \theta \frac{P_{tr}(x_1|y_1)P(y_1|\theta)}{P_{tr}(x_1|\theta)} P_{te}(θ|\{xi\}),
$$

where

$$
P_{te}(θ|\{xi\}) \propto \prod_{i} \sum_{y_i} P_{tr}(x_i|y_i)P(y_i|\theta)P(\theta)
$$

and where i counts over the test data, i.e., these computations are done for the
targets yi for test points xi. The ease with which this can be done depends on
how many integrals or sums are tractable, and whether the posterior over θ can be
represented compactly.


# 1.5 Mudança na Probabilidade _a Priori_

A mudança na probabilidade _a priori_ é um problema comum em modelos generativos simples. Um exemplo popular está relacionado à disponibilidade de modelos de Bayes ingênuos para a filtragem de emails de spam. Em casos de mudança na probabilidade _a priori_, assume-se que um modelo causal na forma de $P(x|y)P(y)$ é válido (veja a figura 1.3) e a regra de Bayes é usada para inferir $P(y|x)$. O Naive Bayes é um modelo que faz essa suposição. A dificuldade surge se a distribuição $P(y)$ mudar entre situações de treinamento e teste. Como y é o que estamos tentando prever, não é surpreendente que esse tipo de mudança nos dados afete a previsão.

Para uma mudança conhecida na $P(y)$ _a priori_, é fácil corrigir. Como se presume que $P(x|y)$ não muda, esse modelo pode ser aprendido diretamente a partir dos dados de treinamento. No entanto, o $P_{tr}(y)$ aprendido não é mais válido e precisa ser substituído pela distribuição _a priori_ conhecida no cenário de teste $P_{te}(y)$.

Se, no entanto, a distribuição $P_{te}(y)$ _a priori_ não for conhecida para o cenário de teste, a situação se torna um pouco mais complicada. Fazer uma previsão

$$
P(y|x) = \frac{P(x|y)P(y)}{P(x)}
$$

não é possível sem o conhecimento de $P(y)$. Mas, dada o modelo $P(x|y)$ e os covariados para os dados de teste, certas distribuições sobre y são mais ou menos prováveis. Considere novamente o exemplo do filtro de spam. Se nos dados de teste, a grande maioria dos emails contiver palavras de spam, em vez de palavras normais, consideraríamos $P(spam) = 0$ como um modelo improvável em comparação com outros modelos, como $P(spam) = 0.7$. Ao dizer isso, estamos implicitamente usando um modelo _a priori_ de quais distribuições $P(spam)$ são aceitáveis para nós e, em seguida, usando os dados para refinar esse modelo.

Reformulando, para considerar a mudança na probabilidade _a priori_ onde a mudança precisa ser especificada, uma distribuição _a priori_ sobre $P(y)$ válido pode ser especificada, e a distribuição posterior sobre $P(y)$ pode ser calculada a partir dos dados de covariados de teste. Em seguida, o alvo previsto é dado pela soma das previsões obtidas para cada $P(y)$ ponderadas pela probabilidade posterior de $P(y)$.

Suponha que $P(y)$ seja parametrizado por $\theta$, e uma distribuição _a priori_ para $P(y)$ seja definida por meio de uma distribuição _a priori_ nos parâmetros $P(\theta)$. Também assuma que o modelo $P_{tr}(x|y)$ tenha sido aprendido a partir dos dados de treinamento. Então, a previsão levando em consideração a incerteza dos parâmetros e os dados de teste observados é

$$
P(y_1|\{x_i\}) = \int d \theta P(y_1|x_1, \theta) P_{te}(\theta|\{x_i\}) \\
= \int d \theta \frac{P_{tr}(x_1|y_1)P(y_1|\theta)}{P_{tr}(x_1|\theta)} P_{te}(θ|\{xi\}),
$$

onde

$$
P_{te}(θ|\{xi\}) \propto \prod_{i} \sum_{y_i} P_{tr}(x_i|y_i)P(y_i|\theta)P(\theta)
$$

e onde i conta os dados de teste, ou seja, esses cálculos são feitos para os alvos yi para os pontos de teste xi. A facilidade com que isso pode ser feito depende de quantas integrais ou somas são tratáveis e se a posteriori sobre θ pode ser representada de forma compacta.