{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import median\n",
    "from sklearn.model_selection import StratifiedKFold  # maintains class proportions when creating folds\n",
    "import auxiliary_functions as aux\n",
    "from classification import train_randomforest_AUC\n",
    "from filters import runAutoFilter\n",
    "from filters import apply_chosenfilterstrategy\n",
    "\n",
    "\n",
    "# Creates a train and test set for each fold of a stratified kfold process,\n",
    "# then calls the train_classifier function and prints the average results\n",
    "def runClassificationExperiment(df, apply_undersampling, unusable_feature_threshold, filter_method, nfeatures):\n",
    "    kf = StratifiedKFold(n_splits=10, shuffle=False)\n",
    "    score_array = []\n",
    "    fold = 0\n",
    "    for train_index, test_index in kf.split(df.iloc[:, :-1], df.iloc[:, -1]):\n",
    "        fold = fold + 1\n",
    "        training_set = df.iloc[train_index, :]\n",
    "        test_set = df.iloc[test_index, :]\n",
    "        training_set, test_set = aux.removeLowFrequencyFeatures_TrainTest(training_set, test_set, unusable_feature_threshold)\n",
    "\n",
    "        if filter_method == \"None\":\n",
    "            X_train, X_test = training_set.iloc[:, :-1], test_set.iloc[:, :-1]\n",
    "        elif filter_method == \"AutoFilter\":\n",
    "            nfeatures_array = aux.set_nfeatures_array(df.shape[1])  # k values to be used (GenAge dataset)\n",
    "            filter_method, nfeatures = runAutoFilter(training_set, apply_undersampling, nfeatures_array)\n",
    "            print(f'AutoFilter InternalCV end. Selected filter strategy : {filter_method} with k = {nfeatures}')\n",
    "            X_train, X_test = apply_chosenfilterstrategy(df, train_index, test_index, filter_method, nfeatures)\n",
    "        else:  # other filter methods\n",
    "            X_train, X_test = apply_chosenfilterstrategy(df, train_index, test_index, filter_method, nfeatures)\n",
    "\n",
    "        y_train, y_test = training_set.iloc[:, -1], test_set.iloc[:, -1]\n",
    "\n",
    "        #Training classifier - AUC Scoring\n",
    "        score = train_randomforest_AUC(X_train, X_test, y_train, y_test, apply_undersampling)\n",
    "        #score = train_randomforest_gmean(X_train, X_test, y_train, y_test, apply_undersampling) #for GMean scoring\n",
    "        score_array.append(score)\n",
    "        print(f\"Fold {fold}. AUC score: {round(score, 3)}\")\n",
    "\n",
    "    print(f\"Median AUC: {round(median(score_array),3)}\")\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Main function: runs a 10-fold cross-validation and returns the AUC results of Random Forest classifiers trained at each fold, and the median AUC value.\n",
    "The input datasets should be formatted as tab-separated spreadsheets with an index column as the first (leftmost) variable, and a binary (0,1) class value in the last (rightmost) position\n",
    "For our test datasets, there are some additional identifier variables which are removed when loading the dataset: STITCH_Code, InteractorsList, InteractorsCount\n",
    "The following experiment parameters that can be set by the user:\n",
    "\n",
    "unusable_feature_threshold: \n",
    "    Features with too few different values are removed in a preprocessing step, removing spurious variables\n",
    "    This works well for binary features, but is not recommended for features with numerical or categorical values\n",
    "    int value (recommended for our test datasets: 10). If set to a value < 0, the threshold filter is not applying\n",
    "    \n",
    "BRF_undersampling:\n",
    "    Whether the classifiers should be trained using balanced datasets to avoid a bias in favour of the majority class\n",
    "    True: undersample training set to a 1:1 ratio (uses BalancedRandomForestClassifier from imblearn.ensemble library).\n",
    "    False: trains classifier with unchanged class balance (Not recommended for imbalanced datasets)\n",
    "    \n",
    "filter_method: \n",
    "    Selected filter scoring strategy. Accepted values: \n",
    "    \"None\": Do not apply a filter to the dataset, and use all predictive features when training the classifier\n",
    "    \"AutoFilter\": Select a candidate filter and k value by testing all combinations in an internal cross-validation\n",
    "    \"InfoGain\": Apply Information Gain filter (uses native implementation from sklearn)\n",
    "    \"Chi2\": Apply Chi2 filter (uses native implementation from sklearn)\n",
    "    \"DecisionStump\": Apply Decision Stump filter (implemented in this project)\n",
    "    \"LogOddsRatio\": Apply Log Odds Ratio filter (implemented in this project)\n",
    "    \"AsymmetricOptimalPrediction\": Apply Asymmetric Optimal Prediction filter (implemented in this project)\n",
    "    \n",
    "nfeatures: number of predictive features to be selected when applying the filter method\n",
    "    int value, irrelevant for filter_method = None (no filter) and for filter_method = AutoFilter (chosen automatically)    \n",
    "\"\"\"\n",
    "def main(filepath, BRF_undersampling, unusable_feature_threshold, filter_method, nfeatures):\n",
    "    if filepath == \"\":\n",
    "        df = aux.load_dataset_dialog()\n",
    "    else:\n",
    "        df = aux.load_dataset_filepath(filepath)\n",
    "    df = aux.removeLowFrequencyFeatures(df, unusable_feature_threshold)  # Apply threshold filter to full dataset (reduce runtime)\n",
    "    runClassificationExperiment(df, BRF_undersampling, unusable_feature_threshold, filter_method, nfeatures)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running InternalCV for AutoFilter. Method: InfoGain k: 250\n",
      "Running InternalCV for AutoFilter. Method: InfoGain k: 500\n",
      "Running InternalCV for AutoFilter. Method: InfoGain k: 750\n",
      "Running InternalCV for AutoFilter. Method: InfoGain k: 1000\n",
      "Running InternalCV for AutoFilter. Method: Chi2 k: 250\n",
      "Running InternalCV for AutoFilter. Method: Chi2 k: 500\n",
      "Running InternalCV for AutoFilter. Method: Chi2 k: 750\n",
      "Running InternalCV for AutoFilter. Method: Chi2 k: 1000\n",
      "Running InternalCV for AutoFilter. Method: DecisionStump k: 250\n",
      "Running InternalCV for AutoFilter. Method: DecisionStump k: 500\n",
      "Running InternalCV for AutoFilter. Method: DecisionStump k: 750\n",
      "Running InternalCV for AutoFilter. Method: DecisionStump k: 1000\n",
      "Running InternalCV for AutoFilter. Method: LogOddsRatio k: 250\n",
      "Running InternalCV for AutoFilter. Method: LogOddsRatio k: 500\n",
      "Running InternalCV for AutoFilter. Method: LogOddsRatio k: 750\n",
      "Running InternalCV for AutoFilter. Method: LogOddsRatio k: 1000\n",
      "Running InternalCV for AutoFilter. Method: AsymmetricOptimalPrediction k: 250\n",
      "Running InternalCV for AutoFilter. Method: AsymmetricOptimalPrediction k: 500\n",
      "Running InternalCV for AutoFilter. Method: AsymmetricOptimalPrediction k: 750\n",
      "Running InternalCV for AutoFilter. Method: AsymmetricOptimalPrediction k: 1000\n",
      "Candidate Filter: InfoGain, k: 250. Median AUC Score: 0.808, AUC variance: 0.006\n",
      "Candidate Filter: InfoGain, k: 500. Median AUC Score: 0.816, AUC variance: 0.007\n",
      "Candidate Filter: InfoGain, k: 750. Median AUC Score: 0.829, AUC variance: 0.007\n",
      "Candidate Filter: InfoGain, k: 1000. Median AUC Score: 0.82, AUC variance: 0.008\n",
      "Candidate Filter: Chi2, k: 250. Median AUC Score: 0.8, AUC variance: 0.009\n",
      "Candidate Filter: Chi2, k: 500. Median AUC Score: 0.81, AUC variance: 0.008\n",
      "Candidate Filter: Chi2, k: 750. Median AUC Score: 0.82, AUC variance: 0.008\n",
      "Candidate Filter: Chi2, k: 1000. Median AUC Score: 0.83, AUC variance: 0.007\n",
      "Candidate Filter: DecisionStump, k: 250. Median AUC Score: 0.808, AUC variance: 0.006\n",
      "Candidate Filter: DecisionStump, k: 500. Median AUC Score: 0.811, AUC variance: 0.006\n",
      "Candidate Filter: DecisionStump, k: 750. Median AUC Score: 0.82, AUC variance: 0.008\n",
      "Candidate Filter: DecisionStump, k: 1000. Median AUC Score: 0.826, AUC variance: 0.007\n",
      "Candidate Filter: LogOddsRatio, k: 250. Median AUC Score: 0.77, AUC variance: 0.008\n",
      "Candidate Filter: LogOddsRatio, k: 500. Median AUC Score: 0.757, AUC variance: 0.006\n",
      "Candidate Filter: LogOddsRatio, k: 750. Median AUC Score: 0.788, AUC variance: 0.005\n",
      "Candidate Filter: LogOddsRatio, k: 1000. Median AUC Score: 0.805, AUC variance: 0.008\n",
      "Candidate Filter: AsymmetricOptimalPrediction, k: 250. Median AUC Score: 0.754, AUC variance: 0.007\n",
      "Candidate Filter: AsymmetricOptimalPrediction, k: 500. Median AUC Score: 0.753, AUC variance: 0.006\n",
      "Candidate Filter: AsymmetricOptimalPrediction, k: 750. Median AUC Score: 0.791, AUC variance: 0.006\n",
      "Candidate Filter: AsymmetricOptimalPrediction, k: 1000. Median AUC Score: 0.796, AUC variance: 0.007\n",
      "Chosen strategy: Chi2_1000. Average score 0.8295584045584047 and variance 0.006741706490856103\n",
      "AutoFilter InternalCV end. Selected filter strategy : Chi2 with k = 1000\n",
      "Applying filter Chi2 with k: 1000\n",
      "Fold 1. AUC score: 0.581\n",
      "Applying filter Chi2 with k: 1000\n",
      "Fold 2. AUC score: 0.644\n",
      "Applying filter Chi2 with k: 1000\n",
      "Fold 3. AUC score: 0.656\n",
      "Applying filter Chi2 with k: 1000\n",
      "Fold 4. AUC score: 0.78\n",
      "Applying filter Chi2 with k: 1000\n",
      "Fold 5. AUC score: 0.84\n",
      "Applying filter Chi2 with k: 1000\n",
      "Fold 6. AUC score: 0.748\n",
      "Applying filter Chi2 with k: 1000\n",
      "Fold 7. AUC score: 0.84\n",
      "Applying filter Chi2 with k: 1000\n",
      "Fold 8. AUC score: 0.851\n",
      "Applying filter Chi2 with k: 1000\n",
      "Fold 9. AUC score: 0.954\n",
      "Applying filter Chi2 with k: 1000\n",
      "Fold 10. AUC score: 0.847\n",
      "Median AUC: 0.81\n"
     ]
    }
   ],
   "source": [
    "# Test parameters\n",
    "filename = 'C Elegans dataset examples\\Version-1 datasets (no score threshold)\\CElegans GOTerms dataset_v1.tsv' # set as empty (\"\") to have a file selection dialog\n",
    "#filename = \"\"  # set as empty (\"\") to have a file selection dialog\n",
    "unusable_feature_threshold = 10  # features with too few different values are removed in a preprocessing step\n",
    "BRF_undersampling = True  # True: undersample the training set to a 1:1 ratio (uses BRF for RF classifiers).\n",
    "filter_method = \"AutoFilter\"\n",
    "nfeatures = 0\n",
    "main(filename, BRF_undersampling, unusable_feature_threshold, filter_method, nfeatures)  # runs main function"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
